kind: Dashboard
metadata:
  name: llm-d-basic-monitoring
  project: default
spec:
  display:
    name: "llm-d Basic Monitoring"
    description: "Basic llm-d monitoring dashboard compatible with Perses"
  duration: 12h
  refreshInterval: 30s
  datasources:
    prometheus:
      default: true
      plugin:
        kind: PrometheusDatasource
        spec:
          directUrl: http://prometheus:9090
  variables:
    - kind: TextVariable
      spec:
        name: namespace
        display:
          name: "Namespace"
          description: "Kubernetes namespace filter"
        allowAllValue: true
        allowMultiple: true
        plugin:
          kind: PrometheusLabelValuesVariable
          spec:
            datasource:
              kind: PrometheusDatasource
              name: prometheus
            labelName: namespace
            matchers: []
    - kind: TextVariable
      spec:
        name: model_name
        display:
          name: "Model Name"
          description: "Model name filter"
        allowAllValue: true
        allowMultiple: true
        plugin:
          kind: PrometheusLabelValuesVariable
          spec:
            datasource:
              kind: PrometheusDatasource
              name: prometheus
            labelName: model_name
            matchers:
              - vllm:generation_tokens_total
  layouts:
    - kind: Grid
      spec:
        display:
          title: "Performance Metrics"
          collapse:
            open: true
        items:
          - x: 0
            y: 0
            width: 12
            height: 8
            content:
              $ref: "#/spec/panels/e2e_request_latency"
          - x: 12
            y: 0
            width: 12
            height: 8
            content:
              $ref: "#/spec/panels/token_throughput"
          - x: 0
            y: 8
            width: 12
            height: 8
            content:
              $ref: "#/spec/panels/time_per_output_token"
          - x: 12
            y: 8
            width: 12
            height: 8
            content:
              $ref: "#/spec/panels/scheduler_state"
          - x: 0
            y: 16
            width: 12
            height: 8
            content:
              $ref: "#/spec/panels/ttft_latency"
          - x: 12
            y: 16
            width: 12
            height: 8
            content:
              $ref: "#/spec/panels/cache_utilization"
  panels:
    e2e_request_latency:
      kind: Panel
      spec:
        display:
          name: "E2E Request Latency"
          description: "End to end request latency measured in seconds."
        plugin:
          kind: TimeSeriesChart
          spec:
            legend:
              position: bottom
            yAxis:
              show: true
              label: "seconds"
              format:
                unit: s
        queries:
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'histogram_quantile(0.99, sum by(le) (rate(vllm:e2e_request_latency_seconds_bucket{namespace=~"$namespace",model_name=~"$model_name"}[5m])))'
                  seriesNameFormat: "P99"
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'histogram_quantile(0.9, sum by(le) (rate(vllm:e2e_request_latency_seconds_bucket{namespace=~"$namespace",model_name=~"$model_name"}[5m])))'
                  seriesNameFormat: "P90"
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'histogram_quantile(0.5, sum by(le) (rate(vllm:e2e_request_latency_seconds_bucket{namespace=~"$namespace",model_name=~"$model_name"}[5m])))'
                  seriesNameFormat: "P50"
    token_throughput:
      kind: Panel
      spec:
        display:
          name: "Token Throughput"
          description: "Number of tokens processed per second"
        plugin:
          kind: TimeSeriesChart
          spec:
            legend:
              position: bottom
            yAxis:
              show: true
              label: "tokens/sec"
        queries:
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'rate(vllm:prompt_tokens_total{namespace=~"$namespace",model_name=~"$model_name"}[5m])'
                  seriesNameFormat: "Prompt Tokens/Sec"
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'rate(vllm:generation_tokens_total{namespace=~"$namespace",model_name=~"$model_name"}[5m])'
                  seriesNameFormat: "Generation Tokens/Sec"
    time_per_output_token:
      kind: Panel
      spec:
        display:
          name: "Time Per Output Token Latency"
          description: "Inter token latency in seconds."
        plugin:
          kind: TimeSeriesChart
          spec:
            legend:
              position: bottom
            yAxis:
              show: true
              label: "seconds"
              format:
                unit: s
        queries:
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'histogram_quantile(0.99, sum by(le) (rate(vllm:time_per_output_token_seconds_bucket{namespace=~"$namespace",model_name=~"$model_name"}[5m])))'
                  seriesNameFormat: "P99"
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'histogram_quantile(0.9, sum by(le) (rate(vllm:time_per_output_token_seconds_bucket{namespace=~"$namespace",model_name=~"$model_name"}[5m])))'
                  seriesNameFormat: "P90"
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'histogram_quantile(0.5, sum by(le) (rate(vllm:time_per_output_token_seconds_bucket{namespace=~"$namespace",model_name=~"$model_name"}[5m])))'
                  seriesNameFormat: "P50"
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'rate(vllm:time_per_output_token_seconds_sum{namespace=~"$namespace",model_name=~"$model_name"}[5m]) / rate(vllm:time_per_output_token_seconds_count{namespace=~"$namespace",model_name=~"$model_name"}[5m])'
                  seriesNameFormat: "Mean"
    scheduler_state:
      kind: Panel
      spec:
        display:
          name: "Scheduler State"
          description: "Number of requests in RUNNING, WAITING, and SWAPPED state"
        plugin:
          kind: TimeSeriesChart
          spec:
            legend:
              position: bottom
            yAxis:
              show: true
              label: "requests"
        queries:
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'vllm:num_requests_running{namespace=~"$namespace",model_name=~"$model_name"}'
                  seriesNameFormat: "Num Running"
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'vllm:num_requests_swapped{namespace=~"$namespace",model_name=~"$model_name"}'
                  seriesNameFormat: "Num Swapped"
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'vllm:num_requests_waiting{namespace=~"$namespace",model_name=~"$model_name"}'
                  seriesNameFormat: "Num Waiting"
    ttft_latency:
      kind: Panel
      spec:
        display:
          name: "Time To First Token Latency"
          description: "P50, P90, P99 TTFT latency in seconds."
        plugin:
          kind: TimeSeriesChart
          spec:
            legend:
              position: bottom
            yAxis:
              show: true
              label: "seconds"
              format:
                unit: s
        queries:
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'histogram_quantile(0.99, sum by(le) (rate(vllm:time_to_first_token_seconds_bucket{namespace=~"$namespace",model_name=~"$model_name"}[5m])))'
                  seriesNameFormat: "P99"
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'histogram_quantile(0.9, sum by(le) (rate(vllm:time_to_first_token_seconds_bucket{namespace=~"$namespace",model_name=~"$model_name"}[5m])))'
                  seriesNameFormat: "P90"
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'histogram_quantile(0.5, sum by(le) (rate(vllm:time_to_first_token_seconds_bucket{namespace=~"$namespace",model_name=~"$model_name"}[5m])))'
                  seriesNameFormat: "P50"
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'rate(vllm:time_to_first_token_seconds_sum{namespace=~"$namespace",model_name=~"$model_name"}[5m]) / rate(vllm:time_to_first_token_seconds_count{namespace=~"$namespace",model_name=~"$model_name"}[5m])'
                  seriesNameFormat: "Average"
    cache_utilization:
      kind: Panel
      spec:
        display:
          name: "Cache Utilization"
          description: "Percentage of used cache blocks by vLLM."
        plugin:
          kind: TimeSeriesChart
          spec:
            legend:
              position: bottom
            yAxis:
              show: true
              label: "utilization"
              format:
                unit: percentunit
        queries:
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'vllm:gpu_cache_usage_perc{namespace=~"$namespace",model_name=~"$model_name"}'
                  seriesNameFormat: "GPU Cache Usage"
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'vllm:cpu_cache_usage_perc{namespace=~"$namespace",model_name=~"$model_name"}'
                  seriesNameFormat: "CPU Cache Usage"

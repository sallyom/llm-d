kind: Dashboard
metadata:
  name: llm-d-failure-saturation
  project: default
spec:
  display:
    name: "llm-d Failure & Saturation Indicators"
    description: "Key failure and saturation indicators for llm-d inference server (Tier 1 metrics)"
  duration: 6h
  refreshInterval: 30s
  datasources:
    prometheus:
      default: true
      plugin:
        kind: PrometheusDatasource
        spec:
          directUrl: http://prometheus:9090
  variables:
    - kind: TextVariable
      spec:
        name: namespace
        display:
          name: "Namespace"
          description: "Kubernetes namespace filter"
        allowAllValue: true
        allowMultiple: true
        plugin:
          kind: PrometheusLabelValuesVariable
          spec:
            datasource:
              kind: PrometheusDatasource
              name: prometheus
            labelName: namespace
            matchers: []
    - kind: TextVariable
      spec:
        name: model_name
        display:
          name: "Model Name"
          description: "Model name filter"
        allowAllValue: true
        allowMultiple: true
        plugin:
          kind: PrometheusLabelValuesVariable
          spec:
            datasource:
              kind: PrometheusDatasource
              name: prometheus
            labelName: model_name
            matchers:
              - vllm:generation_tokens_total
  layouts:
    - kind: Grid
      spec:
        display:
          title: "Failure & Saturation Indicators"
          collapse:
            open: true
        items:
          - x: 0
            y: 0
            width: 6
            height: 6
            content:
              $ref: "#/spec/panels/overall_error_rate"
          - x: 6
            y: 0
            width: 9
            height: 6
            content:
              $ref: "#/spec/panels/per_model_error_rate"
          - x: 15
            y: 0
            width: 9
            height: 6
            content:
              $ref: "#/spec/panels/request_preemptions"
          - x: 0
            y: 6
            width: 8
            height: 8
            content:
              $ref: "#/spec/panels/overall_latency"
          - x: 8
            y: 6
            width: 8
            height: 8
            content:
              $ref: "#/spec/panels/model_ttft_p99"
          - x: 16
            y: 6
            width: 8
            height: 8
            content:
              $ref: "#/spec/panels/model_tpt_p99"
          - x: 0
            y: 14
            width: 4
            height: 4
            content:
              $ref: "#/spec/panels/scheduler_health"
          - x: 4
            y: 14
            width: 10
            height: 8
            content:
              $ref: "#/spec/panels/gpu_utilization"
          - x: 14
            y: 14
            width: 10
            height: 8
            content:
              $ref: "#/spec/panels/request_rate"
          - x: 0
            y: 22
            width: 12
            height: 8
            content:
              $ref: "#/spec/panels/epp_e2e_latency_p99"
          - x: 12
            y: 22
            width: 12
            height: 8
            content:
              $ref: "#/spec/panels/plugin_processing_latency"
  panels:
    overall_error_rate:
      kind: Panel
      spec:
        display:
          name: "Overall Error Rate"
          description: "Overall platform-wide error rate across all models"
        plugin:
          kind: StatChart
          spec:
            calculation: lastNotNull
            format:
              unit: percentunit
            thresholds:
              mode: absolute
              steps:
                - color: green
                  value: 0
                - color: yellow
                  value: 0.01
                - color: red
                  value: 0.05
        queries:
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'sum(rate(inference_model_request_error_total{namespace=~"$namespace"}[5m])) / sum(rate(inference_model_request_total{namespace=~"$namespace"}[5m]))'
                  seriesNameFormat: "Error Rate"
    per_model_error_rate:
      kind: Panel
      spec:
        display:
          name: "Per-Model Error Rate"
          description: "Error rate broken down by model name"
        plugin:
          kind: TimeSeriesChart
          spec:
            legend:
              position: bottom
            yAxis:
              show: true
              label: "error rate"
              format:
                unit: percentunit
        queries:
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'sum by(model_name) (rate(inference_model_request_error_total{namespace=~"$namespace",model_name=~"$model_name"}[5m])) / sum by(model_name) (rate(inference_model_request_total{namespace=~"$namespace",model_name=~"$model_name"}[5m]))'
                  seriesNameFormat: "{{model_name}}"
    request_preemptions:
      kind: Panel
      spec:
        display:
          name: "Request Preemptions"
          description: "Number of request preemptions per vLLM instance (indicates resource contention)"
        plugin:
          kind: TimeSeriesChart
          spec:
            legend:
              position: bottom
            yAxis:
              show: true
              label: "preemptions/sec"
        queries:
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'sum by(pod, instance) (rate(vllm:num_preemptions_total{namespace=~"$namespace",model_name=~"$model_name"}[5m]))'
                  seriesNameFormat: "{{pod}}"
    overall_latency:
      kind: Panel
      spec:
        display:
          name: "Overall Latency P50/P90/P99"
          description: "P50, P90, and P99 overall request latency across all models"
        plugin:
          kind: TimeSeriesChart
          spec:
            legend:
              position: bottom
            yAxis:
              show: true
              label: "seconds"
              format:
                unit: s
        queries:
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'histogram_quantile(0.50, sum by(le) (rate(inference_model_request_duration_seconds_bucket{namespace=~"$namespace",model_name=~"$model_name"}[5m])))'
                  seriesNameFormat: "P50"
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'histogram_quantile(0.90, sum by(le) (rate(inference_model_request_duration_seconds_bucket{namespace=~"$namespace",model_name=~"$model_name"}[5m])))'
                  seriesNameFormat: "P90"
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'histogram_quantile(0.99, sum by(le) (rate(inference_model_request_duration_seconds_bucket{namespace=~"$namespace",model_name=~"$model_name"}[5m])))'
                  seriesNameFormat: "P99"
    model_ttft_p99:
      kind: Panel
      spec:
        display:
          name: "Model-Specific TTFT P99"
          description: "P99 Time to First Token latency by model (measures how long until response starts)"
        plugin:
          kind: TimeSeriesChart
          spec:
            legend:
              position: bottom
            yAxis:
              show: true
              label: "seconds"
              format:
                unit: s
        queries:
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'histogram_quantile(0.99, sum by(le, model_name) (rate(vllm:time_to_first_token_seconds_bucket{namespace=~"$namespace",model_name=~"$model_name"}[5m])))'
                  seriesNameFormat: "{{model_name}}"
    model_tpt_p99:
      kind: Panel
      spec:
        display:
          name: "Model-Specific TPT P99"
          description: "P99 Time per Output Token by model (measures generation speed)"
        plugin:
          kind: TimeSeriesChart
          spec:
            legend:
              position: bottom
            yAxis:
              show: true
              label: "seconds"
              format:
                unit: s
        queries:
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'histogram_quantile(0.99, sum by(le, model_name) (rate(vllm:time_per_output_token_seconds_bucket{namespace=~"$namespace",model_name=~"$model_name"}[5m])))'
                  seriesNameFormat: "{{model_name}}"
    scheduler_health:
      kind: Panel
      spec:
        display:
          name: "Scheduler Health"
          description: "Scheduler uptime and health indicator"
        plugin:
          kind: StatChart
          spec:
            calculation: lastNotNull
            valueMappings:
              - value: 0
                text: "Down"
                color: red
              - value: 1
                text: "Up"
                color: green
            thresholds:
              mode: absolute
              steps:
                - color: red
                  value: 0
                - color: green
                  value: 1
        queries:
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'avg_over_time(up{job="gaie-inference-scheduling-epp",namespace=~"$namespace"}[5m])'
                  seriesNameFormat: "Scheduler"
    gpu_utilization:
      kind: Panel
      spec:
        display:
          name: "GPU Utilization"
          description: "Average GPU utilization across all GPUs"
        plugin:
          kind: TimeSeriesChart
          spec:
            legend:
              position: bottom
            yAxis:
              show: true
              label: "percent"
              format:
                unit: percent
        queries:
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'avg by(gpu, node) (DCGM_FI_DEV_GPU_UTIL{namespace=~"$namespace"} or nvidia_gpu_duty_cycle{namespace=~"$namespace"})'
                  seriesNameFormat: "{{node}}-gpu{{gpu}}"
    request_rate:
      kind: Panel
      spec:
        display:
          name: "Request Rate"
          description: "Request rate (QPS) by model"
        plugin:
          kind: TimeSeriesChart
          spec:
            legend:
              position: bottom
            yAxis:
              show: true
              label: "requests/sec"
              format:
                unit: reqps
        queries:
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'sum by(model_name, target_model_name) (rate(inference_model_request_total{namespace=~"$namespace",model_name=~"$model_name"}[5m]))'
                  seriesNameFormat: "{{model_name}}"
    epp_e2e_latency_p99:
      kind: Panel
      spec:
        display:
          name: "EPP E2E Latency P99"
          description: "P99 end-to-end latency through the EPP scheduler"
        plugin:
          kind: TimeSeriesChart
          spec:
            legend:
              position: bottom
            yAxis:
              show: true
              label: "seconds"
              format:
                unit: s
        queries:
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'histogram_quantile(0.99, sum by(le) (rate(inference_extension_scheduler_e2e_duration_seconds_bucket{namespace=~"$namespace"}[5m])))'
                  seriesNameFormat: "P99"
    plugin_processing_latency:
      kind: Panel
      spec:
        display:
          name: "Plugin Processing Latency"
          description: "P99 plugin processing latency by plugin type"
        plugin:
          kind: TimeSeriesChart
          spec:
            legend:
              position: bottom
            yAxis:
              show: true
              label: "seconds"
              format:
                unit: s
        queries:
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                    name: prometheus
                  query: 'histogram_quantile(0.99, sum by(le, plugin_type) (rate(inference_extension_plugin_duration_seconds_bucket{namespace=~"$namespace"}[5m])))'
                  seriesNameFormat: "{{plugin_type}}"

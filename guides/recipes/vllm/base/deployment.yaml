apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-d-model-server
spec:
  replicas: 2
  selector:
    matchLabels:
      llm-d.ai/inference-serving: "true"
  template:
    metadata:
      labels:
        llm-d.ai/inference-serving: "true"
    spec:
      containers:
        - name: vllm
          image: INFERENCE_SERVER_IMAGE
          imagePullPolicy: IfNotPresent
          command:
            - /bin/bash
            - -c
          args:
            - exec vllm serve --port 8000
              # To enable tracing, add:
              # --otlp-traces-endpoint http://otel-collector:4317
              # --collect-detailed-traces all
          env:
            # To enable tracing, uncomment:
            # - name: OTEL_SERVICE_NAME
            #   value: "vllm"
            # - name: OTEL_EXPORTER_OTLP_ENDPOINT
            #   value: "http://otel-collector:4317"
            # - name: OTEL_TRACES_SAMPLER
            #   value: "parentbased_traceidratio"
            # - name: OTEL_TRACES_SAMPLER_ARG
            #   value: "0.1"
            - name: HUGGING_FACE_HUB_TOKEN
              valueFrom:
                secretKeyRef:
                  name: llm-d-hf-token
                  key: HF_TOKEN
          ports:
            - containerPort: 8000
              name: http
              protocol: TCP
          lifecycle:
            preStop:
              sleep:
                seconds: 30
          livenessProbe:
            httpGet:
              path: /health
              port: http
              scheme: HTTP
            periodSeconds: 1
            successThreshold: 1
            failureThreshold: 5
            timeoutSeconds: 1
          readinessProbe:
            httpGet:
              path: /health
              port: http
              scheme: HTTP
            periodSeconds: 1
            successThreshold: 1
            failureThreshold: 1
            timeoutSeconds: 1
          startupProbe:
            failureThreshold: 600
            initialDelaySeconds: 2
            periodSeconds: 1
            httpGet:
              path: /health
              port: http
              scheme: HTTP
          volumeMounts:
            - mountPath: /data
              name: data
            - mountPath: /dev/shm
              name: shm
      restartPolicy: Always

      enableServiceLinks: false

      terminationGracePeriodSeconds: 130

      volumes:
        - name: data
          emptyDir: {}
        - name: shm
          emptyDir:
            medium: Memory
